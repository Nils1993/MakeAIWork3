{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>In this notebook I will use the AQL functionality and implement a chatbot.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from broncode.apple_classifyer import AppleClassifyer\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "import torch\n",
    "import pickle as pkl\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved model path\n",
    "apple_model_path = \"../models/AppleClassifyer_86\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model using pickle\n",
    "load = open(apple_model_path, \"rb\")\n",
    "apple_classifyer = pkl.load(load)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>I've created a folder with 20 apples in it</h3>\n",
    "\n",
    "-   14 good apples\n",
    "-   2 blotch apples\n",
    "-   1 rot apple\n",
    "-   3 scab apples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a sample for the AQL inspection\n",
    "aql_sample20 = []\n",
    "# Path to the folder I created\n",
    "aql_path = \"../informatie/apple_disease_classification/images/Test/AQL_testbatch/\"\n",
    "\n",
    "for filename in os.listdir(aql_path):\n",
    "    aql_sample20.append(read_image(aql_path+filename, ImageReadMode.RGB)/255)\n",
    "\n",
    "print(aql_sample20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize the images to the shape needed for the model\n",
    "resize = T.Resize((64,64))\n",
    "print(aql_sample20[0].shape)\n",
    "\n",
    "for i in range(len(aql_sample20)):\n",
    "    aql_sample20[i] = resize(aql_sample20[i])\n",
    "    # Use unsqueeze to emulate a batch\n",
    "    aql_sample20[i] = aql_sample20[i].unsqueeze(0)\n",
    "\n",
    "print(aql_sample20[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use aql_classifyer function to inspect the samples. It returns the AQL, amount of good apples and amount of bad apples. It also prints the amount of good apples out of len(sample).\n",
    "aql, good_amount, bad_amount = apple_classifyer.aql_classifyer(aql_sample20)\n",
    "\n",
    "print(f\"AQL quality from code letter F: {aql}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the label and create variables for the chatbot\n",
    "if aql == 0.4:\n",
    "    apple_use = \"Approved for: grocery/greengrocer\"\n",
    "elif aql == 6.5:\n",
    "    apple_use = \"Approved for apple sauce\"\n",
    "elif aql == 15:\n",
    "    apple_use = \"Approved for apple syrup\"\n",
    "elif aql == \"REJECTED\":\n",
    "    apple_use = aql\n",
    "\n",
    "\n",
    "total_apples = good_amount + bad_amount\n",
    "percentage = round((good_amount*100) / total_apples)\n",
    "\n",
    "print(apple_use)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Implementing chatbot</h2>\n",
    "\n",
    "Ask one of these questions after running the cell below:\n",
    "-   What is the AQL of these apples?\n",
    "-   How many good apples are in this sample?\n",
    "-   How many bad apples are in this sample?\n",
    "-   How many apples are in this sample?\n",
    "-   How do you classify your apples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call chatbot\n",
    "chat_model = SentenceTransformer('all-MiniLM-L12-v2')\n",
    "\n",
    "# Use input function to encode the questions asked\n",
    "query_embedding = chat_model.encode(input('What is your question?'))\n",
    "\n",
    "# Give the possible answers\n",
    "possible_answers = [f\"From the {total_apples} apples in this sample {good_amount} are good, so thats {percentage}%.\",\n",
    "                    'How I classify apples is my little secret. >:)',\n",
    "                    f'There are {(total_apples-good_amount)} bad apples in this sample.',\n",
    "                    f\"There are {total_apples} apples in this sample.\",\n",
    "                    f\"The AQL of these apples is {aql}, this means that the use for these apples are: {apple_use}\"]\n",
    "\n",
    "# Encode possible answers\n",
    "passage_embedding = chat_model.encode(possible_answers)\n",
    "\n",
    "# Compare question asked with possible answers to find the best answer\n",
    "answer = util.dot_score(query_embedding, passage_embedding)\n",
    "# Index highest number\n",
    "v, idx = torch.max(answer, 1)\n",
    "# Use the index to give the correct response\n",
    "print(possible_answers[idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
