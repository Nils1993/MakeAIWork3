{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Subset, Dataset, DataLoader, random_split\n",
    "from torch import nn\n",
    "import torch.nn.functional\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "import torch\n",
    "import pickle as pkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 128, 128])\n",
      "tensor([[[0.9059, 0.9059, 0.9059,  ..., 0.9294, 0.9294, 0.9294],\n",
      "         [0.9059, 0.9059, 0.9059,  ..., 0.9294, 0.9294, 0.9294],\n",
      "         [0.9059, 0.9059, 0.9059,  ..., 0.9294, 0.9294, 0.9294],\n",
      "         ...,\n",
      "         [0.9490, 0.9490, 0.9490,  ..., 0.9725, 0.9725, 0.9725],\n",
      "         [0.9529, 0.9529, 0.9529,  ..., 0.9725, 0.9725, 0.9725],\n",
      "         [0.9529, 0.9529, 0.9529,  ..., 0.9725, 0.9725, 0.9725]],\n",
      "\n",
      "        [[0.9216, 0.9216, 0.9216,  ..., 0.9294, 0.9294, 0.9294],\n",
      "         [0.9216, 0.9216, 0.9216,  ..., 0.9294, 0.9294, 0.9294],\n",
      "         [0.9216, 0.9216, 0.9216,  ..., 0.9294, 0.9294, 0.9294],\n",
      "         ...,\n",
      "         [0.9412, 0.9412, 0.9412,  ..., 0.9529, 0.9529, 0.9529],\n",
      "         [0.9451, 0.9451, 0.9451,  ..., 0.9529, 0.9529, 0.9529],\n",
      "         [0.9451, 0.9451, 0.9451,  ..., 0.9529, 0.9529, 0.9529]],\n",
      "\n",
      "        [[0.9569, 0.9569, 0.9569,  ..., 0.9686, 0.9686, 0.9686],\n",
      "         [0.9569, 0.9569, 0.9569,  ..., 0.9686, 0.9686, 0.9686],\n",
      "         [0.9569, 0.9569, 0.9569,  ..., 0.9686, 0.9686, 0.9686],\n",
      "         ...,\n",
      "         [0.9529, 0.9529, 0.9529,  ..., 0.9765, 0.9765, 0.9765],\n",
      "         [0.9569, 0.9569, 0.9569,  ..., 0.9765, 0.9765, 0.9765],\n",
      "         [0.9569, 0.9569, 0.9569,  ..., 0.9765, 0.9765, 0.9765]]])\n"
     ]
    }
   ],
   "source": [
    "path = \"../informatie/apple_disease_classification/images/Train/Dataset/normal_apples/good_apple0.jpg\"\n",
    "img = read_image(path, ImageReadMode.UNCHANGED)/255\n",
    "\n",
    "print(img.shape)\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_path = \"../informatie/apple_disease_classification/images/Train/Dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetAppels(Dataset):\n",
    "    def __init__(self, img_folder_path, transform):\n",
    "\n",
    "        image_folder = ImageFolder(img_folder_path, transform=transform)\n",
    "        len_classes = len(image_folder.class_to_idx)\n",
    "        self.images = [image[0] for image in image_folder]\n",
    "        self.labels = [torch.Tensor(self.labeler(image[1], len_classes)) for image in image_folder]\n",
    "        self.class_dict = image_folder.class_to_idx\n",
    "\n",
    "    def labeler(self, label, len_classes):\n",
    "        result = [0] * len_classes\n",
    "        result[label] = 1\n",
    "        return result\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return [self.images[idx], self.labels[idx]]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.DatasetAppels at 0x266bc8855a0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = DatasetAppels(dataset_path, T.ToTensor())\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "resize = T.Resize((64,64))\n",
    "\n",
    "for i in range(len(dataset.images)):\n",
    "    dataset.images[i] = resize(dataset.images[i])\n",
    "\n",
    "print(dataset.images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([1., 0., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 1., 0., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 1., 0.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.]), tensor([0., 0., 0., 1.])]\n",
      "{'blotch_apples': 0, 'normal_apples': 1, 'rot_apples': 2, 'scab_apples': 3}\n"
     ]
    }
   ],
   "source": [
    "print(dataset.labels)\n",
    "print(dataset.class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "print(dataset.images[0].type())\n",
    "print(dataset.images[1000].type())\n",
    "print(dataset.images[1700].type())\n",
    "print(dataset.images[2200].type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1794 598 597\n"
     ]
    }
   ],
   "source": [
    "generator1 = torch.Generator().manual_seed(13)\n",
    "\n",
    "# create a train test split with 70% train, 30% test\n",
    "train_dataset, test_dataset, val_dataset = random_split(dataset, [0.6, 0.2, 0.2], generator=generator1)\n",
    "\n",
    "# check length of train and test dataset\n",
    "print(len(train_dataset), len(test_dataset), len(val_dataset))\n",
    "\n",
    "# create train and test dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=5, shuffle=False)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "# ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    def __init__(self, img_size=64, c_in=3, loss_func=nn.CrossEntropyLoss()):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(c_in, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn. Conv2d(16, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "\n",
    "            nn.Conv2d(16, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn. Conv2d(32, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(img_size*128, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 4),\n",
    "            nn.Softmax(dim=1)\n",
    "            )\n",
    "        \n",
    "        self.loss_func = loss_func\n",
    "# ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- \n",
    "    def fit(self, train_loader, val_loader, test_loader, epochs, lr, opt_function=torch.optim.Adam):\n",
    "        optimizer = opt_function(self.model.parameters(),lr )\n",
    "        history = []\n",
    "        self.model.to(self.cuda_available())\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            print(\"epoch:\",epoch+1)\n",
    "            self.model.train()\n",
    "            \n",
    "            for batch in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                loss = self.loss_calc(batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "            with torch.no_grad():    \n",
    "                self.model.eval()\n",
    "\n",
    "                val_loss = []\n",
    "                for batch in val_loader:\n",
    "                    loss = self.loss_calc(batch)\n",
    "                    val_loss.append(loss)  \n",
    "            \n",
    "            history.append(sum(val_loss))\n",
    "            print(sum(val_loss))\n",
    "        \n",
    "            print(\"Accuracy:\",self.evaluate_accuracy(test_loader))\n",
    "        return history\n",
    "# ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    def cuda_available(self):\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            return torch.device(\"cuda\")\n",
    "        else:\n",
    "            return torch.device(\"cpu\")\n",
    "# ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "                \n",
    "    def loss_calc(self, batch):\n",
    "        image = batch[0].to(self.cuda_available())\n",
    "        labels = batch[1].to(self.cuda_available())\n",
    "        pred = self(image)        \n",
    "        loss = self.loss_func(pred, labels)\n",
    "        return loss\n",
    "# ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    def evaluate_accuracy(self, test_loader):         \n",
    "        cor_pred = 0\n",
    "        bad_pred = 0\n",
    "        for batch in test_loader:\n",
    "            image, labels = batch\n",
    "            image = image.to(self.cuda_available())\n",
    "            labels = labels.to(self.cuda_available())\n",
    "            pred = self(image)\n",
    "    \n",
    "            _, y_pred = torch.max(pred,1)                       \n",
    "            \n",
    "            for i in range(len(y_pred)):\n",
    "                result = [0] * len(pred[0])\n",
    "\n",
    "                p = int(y_pred[i])\n",
    "                result[p] = 1\n",
    "                if result == labels[i].tolist():\n",
    "                    cor_pred += 1\n",
    "                else:\n",
    "                    bad_pred += 1\n",
    "\n",
    "        acc = cor_pred/(cor_pred + bad_pred) * 100\n",
    "        return acc \n",
    "# -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------    \n",
    "    \n",
    "    def predict(self, image):\n",
    "        image = image.to(self.cuda_available())\n",
    "        pred = self(image)\n",
    "        print(pred)\n",
    "        \n",
    "        _, y_pred = torch.max(pred,1)\n",
    "        print(f\"y_pred: {y_pred}\")                       \n",
    "        \n",
    "        result = [0] * len(pred[0])\n",
    "        print(f\"len(pred[0]): {len(pred[0])}\")\n",
    "\n",
    "        p = int(y_pred[0])\n",
    "        print(f\"p: {p}\")\n",
    "        result[p] = 1\n",
    "\n",
    "        return result\n",
    "# ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # def predict(self, image):\n",
    "    #     image = image.to(self.cuda_available())\n",
    "    #     pred = self(image)\n",
    "    #     _, y_pred = torch.max(pred,1)\n",
    "    #     print(pred)\n",
    "    #     print(f\"y_pred: {y_pred}\")                       \n",
    "        \n",
    "    #     for i in range(len(y_pred)):\n",
    "    #         result = [0] * len(pred[0])\n",
    "    #         print(f\"len(pred[0]): {len(pred[0])}\")\n",
    "\n",
    "    #         p = int(y_pred[i])\n",
    "    #         print(f\"p: {p}\")\n",
    "    #         result[p] = 1\n",
    "\n",
    "    #     return result\n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    def forward(self, data):\n",
    "\n",
    "        return self.model(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "tensor(142.2066, device='cuda:0')\n",
      "Accuracy: 60.200668896321076\n",
      "epoch: 2\n",
      "tensor(140.3283, device='cuda:0')\n",
      "Accuracy: 60.03344481605352\n",
      "epoch: 3\n",
      "tensor(132.7505, device='cuda:0')\n",
      "Accuracy: 66.72240802675586\n",
      "epoch: 4\n",
      "tensor(144.6450, device='cuda:0')\n",
      "Accuracy: 52.675585284280935\n",
      "epoch: 5\n",
      "tensor(126.0354, device='cuda:0')\n",
      "Accuracy: 70.90301003344482\n",
      "epoch: 6\n",
      "tensor(125.3383, device='cuda:0')\n",
      "Accuracy: 71.40468227424749\n",
      "epoch: 7\n",
      "tensor(123.9041, device='cuda:0')\n",
      "Accuracy: 72.5752508361204\n",
      "epoch: 8\n",
      "tensor(126.8973, device='cuda:0')\n",
      "Accuracy: 69.39799331103679\n",
      "epoch: 9\n",
      "tensor(121.9486, device='cuda:0')\n",
      "Accuracy: 74.41471571906354\n",
      "epoch: 10\n",
      "tensor(120.5148, device='cuda:0')\n",
      "Accuracy: 75.4180602006689\n",
      "epoch: 11\n",
      "tensor(119.9213, device='cuda:0')\n",
      "Accuracy: 74.74916387959865\n",
      "epoch: 12\n",
      "tensor(119.2619, device='cuda:0')\n",
      "Accuracy: 76.58862876254182\n",
      "epoch: 13\n",
      "tensor(119.2550, device='cuda:0')\n",
      "Accuracy: 76.58862876254182\n",
      "epoch: 14\n",
      "tensor(120.5484, device='cuda:0')\n",
      "Accuracy: 75.25083612040135\n",
      "epoch: 15\n",
      "tensor(120.1513, device='cuda:0')\n",
      "Accuracy: 75.75250836120402\n",
      "epoch: 16\n",
      "tensor(118.7408, device='cuda:0')\n",
      "Accuracy: 76.92307692307693\n",
      "epoch: 17\n",
      "tensor(120.5951, device='cuda:0')\n",
      "Accuracy: 76.75585284280938\n",
      "epoch: 18\n",
      "tensor(116.5665, device='cuda:0')\n",
      "Accuracy: 80.60200668896321\n",
      "epoch: 19\n",
      "tensor(114.8168, device='cuda:0')\n",
      "Accuracy: 80.60200668896321\n",
      "epoch: 20\n",
      "tensor(118.1564, device='cuda:0')\n",
      "Accuracy: 78.09364548494983\n",
      "epoch: 1\n",
      "tensor(113.5486, device='cuda:0')\n",
      "Accuracy: 81.93979933110369\n",
      "epoch: 2\n",
      "tensor(113.5649, device='cuda:0')\n",
      "Accuracy: 81.43812709030101\n",
      "epoch: 3\n",
      "tensor(113.1128, device='cuda:0')\n",
      "Accuracy: 81.60535117056857\n",
      "epoch: 4\n",
      "tensor(113.0336, device='cuda:0')\n",
      "Accuracy: 81.27090301003345\n",
      "epoch: 5\n",
      "tensor(112.8461, device='cuda:0')\n",
      "Accuracy: 82.10702341137124\n",
      "epoch: 6\n",
      "tensor(112.8431, device='cuda:0')\n",
      "Accuracy: 81.77257525083613\n",
      "epoch: 7\n",
      "tensor(112.7750, device='cuda:0')\n",
      "Accuracy: 81.93979933110369\n",
      "epoch: 8\n",
      "tensor(112.5669, device='cuda:0')\n",
      "Accuracy: 82.6086956521739\n",
      "epoch: 9\n",
      "tensor(112.6349, device='cuda:0')\n",
      "Accuracy: 82.6086956521739\n",
      "epoch: 10\n",
      "tensor(113.0372, device='cuda:0')\n",
      "Accuracy: 83.11036789297658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor(113.5486, device='cuda:0'),\n",
       " tensor(113.5649, device='cuda:0'),\n",
       " tensor(113.1128, device='cuda:0'),\n",
       " tensor(113.0336, device='cuda:0'),\n",
       " tensor(112.8461, device='cuda:0'),\n",
       " tensor(112.8431, device='cuda:0'),\n",
       " tensor(112.7750, device='cuda:0'),\n",
       " tensor(112.5669, device='cuda:0'),\n",
       " tensor(112.6349, device='cuda:0'),\n",
       " tensor(113.0372, device='cuda:0')]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loop over dataloader and push images and labels to device\n",
    "# dataset.images.to(\"cuda\")\n",
    "# dataset.labels.to(\"cuda\")\n",
    "\n",
    "net = CNN()\n",
    "\n",
    "net.fit(train_loader, val_loader, test_loader, lr = 0.00015, epochs=20)\n",
    "net.fit(train_loader, val_loader, test_loader, lr = 0.00003, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"..//models/CNN_83\"\n",
    "\n",
    "with open(model_path, 'wb') as f:\n",
    "        pkl.dump(net, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.9409e-01, 6.0565e-10, 4.2505e-07, 5.9122e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[9.9409e-01, 6.0565e-10, 4.2505e-07, 5.9122e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "y_pred: tensor([0], device='cuda:0')\n",
      "len(pred[0]): 4\n",
      "p: 0\n",
      "[1, 0, 0, 0]\n",
      "tensor([[8.2813e-01, 4.7337e-08, 1.7187e-01, 1.4833e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[8.2813e-01, 4.7337e-08, 1.7187e-01, 1.4833e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "y_pred: tensor([0], device='cuda:0')\n",
      "len(pred[0]): 4\n",
      "p: 0\n",
      "[1, 0, 0, 0]\n",
      "tensor([[9.9821e-01, 3.4643e-08, 5.3012e-05, 1.7360e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[9.9821e-01, 3.4643e-08, 5.3012e-05, 1.7360e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "y_pred: tensor([0], device='cuda:0')\n",
      "len(pred[0]): 4\n",
      "p: 0\n",
      "[1, 0, 0, 0]\n",
      "tensor([[5.4494e-01, 2.1900e-10, 9.5030e-07, 4.5506e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[5.4494e-01, 2.1900e-10, 9.5030e-07, 4.5506e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "y_pred: tensor([0], device='cuda:0')\n",
      "len(pred[0]): 4\n",
      "p: 0\n",
      "[1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "load = open(model_path, \"rb\")\n",
    "loaded_net = pkl.load(load)\n",
    "\n",
    "normal = [120,121,122,123]\n",
    "\n",
    "for i in normal:\n",
    "    test_path = f\"../informatie/apple_disease_classification/images/Test/blotch_Apple/{i}.jpg\"\n",
    "    test_img = read_image(test_path, ImageReadMode.UNCHANGED)/255\n",
    "\n",
    "    test_img = resize(test_img)\n",
    "    print(net(test_img.unsqueeze(0).to(\"cuda\")))\n",
    "    test_img = test_img.unsqueeze(0)\n",
    "    result = loaded_net.predict(test_img)\n",
    "    print(result)\n",
    "    # test_img.shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\nilsm\\\\workspace\\\\MakeAIWork3\\\\Project 3\\\\notebooks'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8.3434e-04, 4.0685e-09, 9.9917e-01, 4.1260e-08]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "y_pred: tensor([2], device='cuda:0')\n",
      "len(pred[0]): 4\n",
      "p: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.predict(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_accuracy(self, test_loader):         \n",
    "#         cor_pred = 0\n",
    "#         bad_pred = 0\n",
    "#         for batch in test_loader:\n",
    "#             image, labels = batch\n",
    "#             image = image.to(self.cuda_available())\n",
    "#             labels = labels.to(self.cuda_available())\n",
    "#             result = self.predict(image)\n",
    "\n",
    "#             for i in range(len(result)):\n",
    "\n",
    "#                 if result == labels[i].tolist():\n",
    "#                     cor_pred += 1\n",
    "#                 else:\n",
    "#                     bad_pred += 1\n",
    "\n",
    "#         acc = cor_pred/(cor_pred + bad_pred) * 100\n",
    "#         return acc     \n",
    "    \n",
    "#     def predict(self, image):\n",
    "#         pred = self(image)\n",
    "#         _, y_pred = torch.max(pred,1)                       \n",
    "        \n",
    "#         for i in range(len(y_pred)):\n",
    "#             result = [0] * len(pred[0])\n",
    "\n",
    "#             p = int(y_pred[i])\n",
    "#             result[p] = 1\n",
    "\n",
    "#         return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Trying a pretrained model (Resnet152V2)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\nilsm/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "C:\\Users\\nilsm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nilsm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to C:\\Users\\nilsm/.cache\\torch\\hub\\checkpoints\\resnet152-394f9c45.pth\n",
      "100%|| 230M/230M [00:08<00:00, 30.2MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (23): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (24): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (25): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (26): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (27): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (28): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (29): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (30): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (31): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (32): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (33): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (34): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (35): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resnet variants:\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.9598e+00,  3.5746e+00,  4.3911e+00,  1.0403e+01,  7.6322e+00,\n",
       "          1.2510e+01,  1.3622e+01, -9.8779e+00, -1.0966e+01, -1.1457e+01,\n",
       "         -1.1623e+00, -6.4075e+00, -6.8714e+00,  2.2168e+00, -3.3824e+00,\n",
       "          3.4502e-01, -6.0733e+00, -3.8418e+00,  2.3481e-01, -7.1640e+00,\n",
       "         -5.6220e-01, -2.6839e+00, -2.9500e+00, -4.4038e+00, -1.8613e+00,\n",
       "          9.1596e-01,  9.4481e+00,  5.2414e+00,  1.0556e+01,  2.0712e+01,\n",
       "          9.8912e+00,  7.3717e+00,  3.2001e+00,  5.4528e-01, -6.3347e+00,\n",
       "          9.0478e-01,  3.9063e+00, -4.9102e+00,  1.8355e+00, -2.1759e+00,\n",
       "          4.4712e+00, -3.2462e+00, -9.9700e+00, -7.9604e-01, -4.5329e+00,\n",
       "         -3.7040e+00,  5.1636e+00,  5.9382e+00, -3.1308e+00, -6.8928e+00,\n",
       "         -3.3628e-01,  9.0688e+00, -1.5167e+00,  1.6840e+00, -3.9321e-01,\n",
       "          1.1465e+01, -2.5647e+00, -3.0674e+00,  4.7294e+00,  5.5021e+00,\n",
       "         -8.5412e-01,  3.8644e+00, -1.0555e+00, -5.0615e+00,  1.2482e+01,\n",
       "          2.1894e+00,  4.8014e+00, -4.0313e+00, -2.1605e+00,  4.0449e-01,\n",
       "          4.1844e+00,  5.1013e+00, -1.1568e+00,  7.1656e-01,  3.3924e+00,\n",
       "          1.6304e+00,  5.1743e+00,  4.1229e+00,  1.4064e+01,  2.0237e-01,\n",
       "         -7.8670e+00, -9.0429e+00, -1.0538e+01, -3.2394e+00, -3.1767e-01,\n",
       "         -6.3862e+00, -1.0822e+01,  1.5533e+00, -2.4177e+00, -5.7304e-01,\n",
       "         -6.5672e+00, -9.3966e+00, -7.4793e+00, -6.3377e+00,  1.0456e+00,\n",
       "          4.1411e+00,  2.0780e+00, -4.1587e-01, -6.1138e+00, -8.8441e-01,\n",
       "         -5.3746e+00, -7.3415e-01, -1.1409e+01, -1.4047e+00, -1.7639e+00,\n",
       "          6.1680e-01,  1.5276e+00,  1.7535e+01,  9.2676e+00,  5.5977e+00,\n",
       "          1.0714e+01,  2.3458e+01,  1.2717e+01,  9.5367e+00,  1.8099e+01,\n",
       "          9.1084e+00,  6.5689e+00,  1.8980e+01,  5.8661e+00,  1.5145e+00,\n",
       "          2.1564e+00,  4.7296e+00,  1.3562e+01,  5.0050e+00,  1.0295e+01,\n",
       "          1.0223e+01,  2.6895e+00, -5.0105e-01, -3.4249e+00, -5.7341e+00,\n",
       "         -8.1691e+00,  1.4319e+00,  8.1273e+00, -3.4189e+00, -3.2533e+00,\n",
       "         -7.6529e+00, -6.2708e+00, -4.2281e+00, -6.9807e+00, -8.1491e+00,\n",
       "          2.5729e+00, -4.9730e+00, -5.6094e+00, -5.5091e+00, -5.9945e+00,\n",
       "         -4.8157e-01,  2.8996e-01,  5.9383e-01, -1.4191e+00,  7.9166e+00,\n",
       "          1.9821e+00, -5.5839e+00, -3.6232e+00,  2.4749e+00, -8.2734e+00,\n",
       "         -4.1930e+00, -3.1060e+00, -4.8556e+00, -4.0137e+00, -4.9697e+00,\n",
       "          7.7573e-01,  1.3483e+00, -4.0835e+00, -4.8079e+00, -5.5064e+00,\n",
       "         -3.4502e+00, -2.9455e+00, -2.5256e+00, -3.5954e+00, -5.5182e+00,\n",
       "         -8.6454e+00, -9.0926e+00,  4.2828e+00, -6.5936e+00, -5.2943e+00,\n",
       "         -1.0372e+01, -1.8774e+00, -3.1231e+00, -2.1954e+00,  2.2832e+00,\n",
       "         -2.4327e-01, -2.7690e+00, -8.1054e+00, -6.3179e+00, -5.5891e+00,\n",
       "         -5.1373e+00, -7.0190e+00, -4.4841e+00, -7.1916e+00, -7.2760e+00,\n",
       "         -7.1439e+00, -2.0433e-01, -6.4374e+00, -4.0563e-01, -9.6507e+00,\n",
       "         -8.9560e-01, -8.7779e-02, -3.4771e+00, -7.1973e+00, -5.1744e+00,\n",
       "         -7.2767e+00, -9.0173e+00, -6.4014e+00,  2.0617e-01, -4.4224e+00,\n",
       "         -2.6256e+00, -4.2810e+00, -1.2988e+00,  2.7438e+00, -5.6495e+00,\n",
       "         -7.8685e+00, -4.8445e+00,  5.5229e+00,  2.7205e+00,  2.9228e+00,\n",
       "         -1.0095e+01, -7.2880e+00, -8.7415e-01, -3.7812e+00, -5.5747e-01,\n",
       "         -4.4390e+00, -3.1054e+00, -7.3990e-01, -6.2248e+00, -5.0208e-01,\n",
       "         -4.8729e+00, -3.7791e+00, -5.7952e+00, -1.0138e+01, -3.8210e+00,\n",
       "         -9.2245e+00, -5.1199e+00, -5.1057e+00, -8.4458e+00, -1.1190e+00,\n",
       "         -2.0023e-01, -9.3488e-01, -2.0413e+00, -5.0364e+00, -1.0094e+01,\n",
       "         -8.6474e+00, -7.9580e+00, -7.5869e-01, -7.3805e+00, -1.3345e+01,\n",
       "         -1.0746e+00,  1.3094e+00, -6.0729e+00,  3.5356e-01,  2.6428e+00,\n",
       "          2.2735e+00,  3.1836e-03, -9.2086e+00, -7.1576e+00, -7.0276e+00,\n",
       "         -9.7461e+00, -3.6409e+00,  8.3769e-01,  7.3386e-01, -3.1489e+00,\n",
       "         -1.6588e+00, -5.5458e+00, -1.3265e+01, -1.1494e+01, -6.4427e+00,\n",
       "         -3.2140e+00, -1.1610e+01, -1.1328e+01, -1.9147e+00, -3.8890e+00,\n",
       "         -3.0455e+00, -4.3178e+00, -8.1358e+00, -4.0859e+00, -4.6100e+00,\n",
       "         -3.0764e-01,  3.2071e+00, -5.9960e+00, -8.1205e+00,  1.0906e+00,\n",
       "         -3.5298e+00,  7.6670e+00,  3.6878e+00,  3.4932e+00,  1.0236e+01,\n",
       "          7.0884e+00,  4.0013e+00, -5.0651e-01, -1.0116e+00,  2.4518e+00,\n",
       "         -2.0469e-01, -3.2556e+00,  7.9811e-02, -1.1202e+01, -6.3201e+00,\n",
       "         -5.8423e+00,  2.9248e+00, -8.6835e+00, -4.9343e+00, -5.1823e+00,\n",
       "          7.1815e+00,  7.3637e+00, -1.7979e+00, -2.7996e+00, -2.6509e+00,\n",
       "         -4.1190e+00,  7.7561e+00, -3.0165e+00,  6.6275e+00,  7.2717e+00,\n",
       "          1.5832e+01, -4.3265e+00,  4.2943e+00,  4.7063e+00,  4.8172e+00,\n",
       "          1.1630e+01,  4.0226e+00,  6.1795e+00,  7.0674e+00,  3.0966e+00,\n",
       "          3.4765e+00, -4.1424e+00,  5.0085e-01, -2.7334e+00,  1.4343e+01,\n",
       "          6.4612e+00,  3.2751e+00,  1.1789e+01,  8.9432e+00,  1.1868e+01,\n",
       "         -1.7872e+00, -2.2820e+00,  6.7583e+00,  9.5025e+00, -4.1702e+00,\n",
       "         -5.3124e+00, -1.1094e+01, -1.3780e+00,  6.4923e+00, -8.7110e+00,\n",
       "         -3.2185e+00, -9.8391e-01, -6.6015e+00, -4.0576e+00, -6.2477e+00,\n",
       "         -4.5018e+00, -1.5824e+00, -4.0882e+00, -1.0703e+01, -1.0804e+01,\n",
       "         -1.4578e+01, -3.7490e+00, -6.2585e+00, -1.3670e+00, -5.6758e+00,\n",
       "          1.2368e+00,  1.4780e+00, -1.1855e+00, -2.8905e-02, -1.2252e+00,\n",
       "         -2.2231e+00, -2.1258e+00, -4.2368e+00, -1.0481e+01,  2.2775e+00,\n",
       "          2.3864e+00, -4.3922e+00, -5.7592e+00, -9.0881e+00, -3.0866e+00,\n",
       "         -3.2228e+00, -6.1774e+00, -1.4791e+01, -7.3041e+00, -4.9103e+00,\n",
       "          5.7963e+00, -6.0552e+00,  1.3675e+00, -2.5533e+00, -4.2602e+00,\n",
       "          2.5460e-01, -6.8300e+00, -2.7129e+00, -3.4889e+00,  4.4082e+00,\n",
       "         -1.9532e-01, -4.2722e+00, -6.3133e+00, -3.0869e+00, -1.1020e-01,\n",
       "          7.4699e+00, -1.5566e+00, -2.7163e-03, -3.9592e-01,  1.5505e+00,\n",
       "         -3.1036e+00, -4.1186e+00,  4.5183e+00, -2.1316e+00, -4.9983e+00,\n",
       "         -9.3813e+00,  1.5958e-01, -2.6051e+00, -6.4322e+00, -7.6268e+00,\n",
       "         -5.2626e+00, -9.6627e-01, -1.4778e+01, -7.7675e+00,  1.0477e+01,\n",
       "         -3.2665e-02, -5.3589e+00,  5.0997e+00, -6.9484e+00, -2.2399e+00,\n",
       "          1.6735e+01, -7.4604e+00, -5.9070e+00, -6.9722e+00, -2.0207e+00,\n",
       "          6.0471e+00, -1.0965e+00, -2.6530e+00, -2.5035e-01,  3.3190e-01,\n",
       "         -7.0844e+00,  1.0574e+01,  6.2574e-01,  3.8729e-01, -3.1857e-01,\n",
       "         -1.5166e+01,  1.4922e+00, -1.1651e+00,  4.7008e+00,  1.6439e+00,\n",
       "          9.2660e+00, -1.4602e+01, -9.3715e+00,  2.7323e+00, -9.8331e+00,\n",
       "          2.5838e+00,  6.1725e+00, -9.8563e+00,  2.3362e+01, -1.0996e+01,\n",
       "         -7.1747e+00, -9.3095e+00, -6.6688e+00,  8.4768e+00, -4.9109e+00,\n",
       "         -8.6071e+00,  6.8860e+00,  9.9022e+00, -5.9368e+00, -4.8014e+00,\n",
       "          1.6720e+01, -5.7179e+00,  5.3390e+00, -2.1958e+00,  1.9774e+00,\n",
       "         -9.9682e+00,  4.8930e+00, -6.5418e-01,  2.5807e+00, -6.4616e-01,\n",
       "         -2.7652e+00,  4.3020e-01, -9.0923e-01, -1.2094e+01,  6.2065e+00,\n",
       "          1.4915e+01, -2.9189e+00, -7.1524e+00,  6.1508e+00, -1.0617e+00,\n",
       "          2.1661e-01,  7.3172e+00, -8.4556e+00, -9.9569e+00, -5.7250e+00,\n",
       "         -3.9531e+00,  1.6482e-01, -6.5088e+00, -6.1209e+00, -1.2738e+01,\n",
       "          5.8866e+00, -6.7077e+00,  3.4769e-01,  3.7244e+00, -4.6233e+00,\n",
       "         -3.1181e+00, -1.9510e+00,  1.1306e+00, -1.0551e+00,  3.1993e+00,\n",
       "          4.7478e+00,  5.9068e+00, -3.5361e+00, -3.7304e+00,  9.6715e+00,\n",
       "         -1.3169e+01, -1.1003e+00,  2.6464e+00, -2.1742e+00,  5.7812e+00,\n",
       "          3.7707e+00,  1.8525e+00, -4.3684e+00,  5.9759e+00, -1.1142e-01,\n",
       "         -7.8712e+00, -9.2703e+00, -3.9992e+00, -6.0846e+00, -3.1856e+00,\n",
       "          1.3474e+01,  3.5673e+00, -9.8429e+00, -4.4310e-01, -5.7694e-02,\n",
       "         -1.0899e+00,  1.1548e+01, -9.7839e+00, -6.4112e+00, -2.4508e+00,\n",
       "         -2.2353e+00,  3.2388e-01, -8.4894e-01,  1.2439e+01,  3.2484e+00,\n",
       "          4.4153e+00, -4.5189e+00,  5.7155e+00, -6.2882e+00,  2.4022e+00,\n",
       "          3.4917e+00, -3.2853e+00, -9.6998e+00, -8.9944e+00, -3.0900e+00,\n",
       "         -8.7820e+00,  5.4280e+00,  5.9880e+00, -3.8162e+00,  3.0254e+00,\n",
       "          9.0663e+00,  4.5368e-01, -6.2454e+00, -3.2160e+00,  2.4909e+00,\n",
       "         -3.1150e+00,  1.5039e+01,  6.1490e+00, -8.9153e+00, -1.0276e+01,\n",
       "         -1.1401e+01, -4.1547e+00, -1.1949e+01, -2.7083e+00, -2.2955e+00,\n",
       "         -4.0088e+00, -4.9345e+00,  3.9503e-01, -5.7579e-01, -4.7246e+00,\n",
       "         -3.1134e+00,  8.1269e-01,  1.8275e+01, -4.2267e+00, -8.7393e+00,\n",
       "          1.8304e+00,  2.6080e-01,  6.6543e+00, -1.0711e+01,  5.4719e+00,\n",
       "         -6.3119e+00, -1.1938e+01,  1.0593e+01, -1.6769e+00, -9.8224e+00,\n",
       "          1.5875e+00, -3.8267e+00,  1.1731e+01, -5.6383e+00,  1.0893e+01,\n",
       "         -3.7762e+00, -9.1762e-01, -5.7233e+00, -1.0905e-01, -2.0623e+00,\n",
       "         -1.4726e+00,  9.3720e+00, -5.0580e-02,  2.1468e+00, -2.3651e+00,\n",
       "          5.6557e+00,  1.2568e-01, -5.8954e+00, -4.2163e+00,  1.0489e-01,\n",
       "          9.3378e+00, -3.4791e+00, -7.6607e+00, -3.6418e+00,  3.3241e+00,\n",
       "          3.4324e+00,  5.4396e+00,  7.4769e+00, -3.3812e+00, -2.5705e+00,\n",
       "         -3.6473e+00, -4.4046e+00, -1.1470e+01,  5.4802e+00, -8.3573e+00,\n",
       "         -7.2720e+00, -3.6124e+00, -1.8697e+00,  9.7177e+00,  3.8140e+00,\n",
       "          4.3968e+00, -1.5954e+00, -3.7090e+00, -8.1197e-01, -1.1756e+01,\n",
       "         -1.1617e+01, -8.2642e-01, -5.5830e+00, -8.4569e+00,  3.7489e+00,\n",
       "         -1.3208e+01,  1.9464e+01, -1.6928e+00,  3.1854e+00, -3.6622e+00,\n",
       "          2.2678e+00, -1.4797e+00,  1.4793e+00, -4.8315e+00, -6.7944e+00,\n",
       "         -5.6487e+00,  7.5469e+00, -6.1137e+00,  1.2665e+01, -7.2583e+00,\n",
       "         -3.8402e+00, -5.3367e+00,  1.6246e+00,  6.5865e+00,  5.1092e+00,\n",
       "         -1.8919e+00,  2.0569e+00, -3.1458e+00, -1.3906e+00, -9.5180e+00,\n",
       "         -8.7216e+00, -8.4412e+00, -3.7265e+00,  5.4774e+00,  1.2368e+01,\n",
       "          4.5442e+00, -8.6286e+00, -1.4367e+00, -1.2359e+01, -2.9101e+00,\n",
       "          3.7185e+00,  1.7517e+01, -1.8803e+00, -3.2286e+00, -3.3329e+00,\n",
       "          8.3570e-01, -6.8716e+00, -4.4259e+00,  1.3094e+01,  5.1579e-01,\n",
       "         -1.8415e+01, -6.5508e+00,  1.8454e-02,  7.7693e+00,  1.3242e+01,\n",
       "          1.6176e+01, -5.7847e+00, -5.0675e+00, -6.4646e+00,  1.7927e+01,\n",
       "          4.8027e+00, -4.1473e+00, -1.2133e+01,  3.2570e+00, -1.8870e+00,\n",
       "         -4.7616e+00,  9.0735e+00,  6.3687e+00, -5.3545e+00, -9.8170e+00,\n",
       "         -1.3430e+00,  1.0221e+01,  2.9186e+00, -7.9096e+00, -5.2588e+00,\n",
       "          1.1571e+01, -7.1099e+00, -1.2041e+01, -3.8438e+00,  1.6561e+00,\n",
       "         -6.9053e+00, -4.7224e+00, -9.8949e-01,  1.7974e+00, -4.6882e+00,\n",
       "         -1.2611e+00,  4.1135e+00,  2.1179e+01,  2.6527e+00,  1.4914e+01,\n",
       "         -4.4641e+00,  1.6021e+00, -8.1028e+00, -7.7733e+00,  9.1741e+00,\n",
       "          6.1166e+00,  1.8465e+00,  5.0628e+00,  6.7357e-01, -1.1202e+01,\n",
       "          1.5191e+01, -9.2398e+00, -4.1482e+00, -2.2751e+00,  1.3839e+01,\n",
       "         -1.5135e+00,  6.1637e+00, -8.0284e+00, -8.0298e+00, -1.4145e+01,\n",
       "         -4.6178e+00, -3.5458e+00,  7.4816e+00,  8.4518e+00,  1.0608e+01,\n",
       "         -7.0000e+00, -7.9856e+00,  2.3446e+00, -7.8987e+00, -3.2885e-02,\n",
       "         -1.4430e+00,  3.8467e+00, -4.1806e+00,  1.8537e+00, -7.1129e+00,\n",
       "         -1.7643e+00, -6.9948e+00, -2.2414e+00,  5.8256e+00, -1.1611e+00,\n",
       "          2.1768e+00,  8.3361e+00,  1.7731e+00, -5.2648e+00, -5.1410e+00,\n",
       "          1.5153e+00,  6.8268e+00,  6.5486e-01, -4.1515e+00, -7.2586e+00,\n",
       "         -5.7410e+00,  7.9708e-01,  1.2691e+01, -4.1500e-01,  2.9334e+00,\n",
       "         -5.3161e+00, -1.0969e+01,  5.4818e+00,  1.7456e+01, -4.1128e+00,\n",
       "         -2.8367e-02, -3.5691e+00, -3.2966e+00,  7.1536e+00, -5.6443e+00,\n",
       "         -1.2276e+01, -1.1056e+01,  1.0342e+00,  8.0809e+00, -1.2036e+00,\n",
       "          1.8972e+00,  3.0344e+00,  9.8452e+00, -4.8884e+00, -6.4799e+00,\n",
       "         -1.8308e+00, -1.9719e+00,  1.7515e+00,  8.4634e+00, -7.7049e-01,\n",
       "         -9.1548e+00, -6.0727e+00,  3.5595e+00, -9.9882e-01, -5.5146e+00,\n",
       "         -4.9908e+00,  2.1821e+00, -5.7679e+00, -4.5288e+00,  1.2531e+01,\n",
       "         -2.1549e+00,  7.2751e-01, -6.3580e+00,  6.6090e+00,  1.9743e+01,\n",
       "          1.3006e+00, -8.1258e-01, -6.3564e+00,  6.2508e+00, -1.2867e+01,\n",
       "          3.3185e+00,  7.1716e+00, -1.1231e+01,  1.0937e+01, -6.8180e+00,\n",
       "          2.6882e+00, -1.6535e+01,  5.6337e+00, -3.3638e+00,  4.1682e+00,\n",
       "         -2.3258e+00,  6.7045e+00, -1.6567e+00,  1.2558e+00, -4.7694e+00,\n",
       "         -7.6857e+00, -5.3462e-01, -2.9943e+00, -5.6525e+00, -9.8489e+00,\n",
       "          4.0134e+00, -5.3055e+00, -5.6397e+00,  6.1884e+00, -7.3221e+00,\n",
       "         -2.9377e+00, -7.2846e+00, -4.6600e+00, -8.5638e+00,  1.8821e+00,\n",
       "          9.9831e+00, -7.8666e-01,  1.7677e+00, -4.8875e+00,  1.0730e+01,\n",
       "          2.3584e+00,  2.7076e+00,  5.0888e+00, -6.4379e+00, -2.8958e+00,\n",
       "          1.1029e+01,  1.2706e-01, -5.6056e+00, -6.4319e-01,  5.8977e+00,\n",
       "         -5.8290e+00,  2.5649e+01, -1.0761e+01, -6.0191e+00, -6.8884e+00,\n",
       "         -4.8873e+00,  1.0148e+01, -6.2412e+00,  1.6220e+01, -1.1370e+01,\n",
       "         -3.5780e+00, -9.1565e+00, -1.0466e+01, -3.0195e+00, -6.7294e+00,\n",
       "         -7.2071e+00,  7.3023e+00, -7.3432e+00,  2.8086e+00, -9.5128e+00,\n",
       "         -6.0788e+00, -6.4983e+00, -8.7363e+00,  1.6833e+01, -9.8688e-01,\n",
       "          5.3705e+00,  9.9857e+00,  2.7611e+00, -7.8704e+00, -4.1094e+00,\n",
       "         -1.2112e+01,  4.0194e+00,  1.3334e+01, -4.6892e+00, -4.0156e+00,\n",
       "         -1.0027e+00,  1.1259e+01,  5.5216e+00,  8.1300e+00,  6.6744e+00,\n",
       "         -3.7615e+00,  1.1471e+01, -2.2822e+00,  1.5516e+00, -8.4966e-01,\n",
       "         -4.6688e+00, -4.6877e+00,  2.0112e+00, -1.3618e+01,  1.1442e+01,\n",
       "          6.5949e+00, -2.3535e-01, -3.6165e+00,  3.3561e+00, -1.1162e+01,\n",
       "         -4.2241e+00, -2.9241e+00, -2.0112e+00, -6.8781e-01, -3.5891e+00,\n",
       "         -6.0684e+00, -1.6822e+00,  1.3090e+00,  2.1753e+01,  1.6359e+01,\n",
       "          1.5868e+01,  9.8032e+00,  1.3163e+01,  1.8595e+01,  1.1644e+01,\n",
       "          3.6154e+00,  2.8156e+01,  2.0014e+01,  9.4529e+00,  5.8362e+00,\n",
       "          2.2340e+01,  2.5535e+01,  1.4834e+01,  1.6983e+01,  2.3567e+01,\n",
       "          1.9738e+01,  2.2448e+01,  1.8294e+01,  4.9524e+01,  8.1162e+00,\n",
       "          2.6708e+01, -3.8173e-01,  1.6864e+01,  3.0807e+01,  1.8760e+01,\n",
       "          1.0033e+01,  1.8380e+01,  1.7670e+01,  1.3797e+01,  2.1454e+01,\n",
       "          9.2553e+00,  2.6518e+01,  8.3132e+00, -3.0619e+00,  4.8919e+00,\n",
       "          6.1683e+00,  1.1458e+01,  6.9155e+00,  9.0979e+00,  1.9560e+01,\n",
       "          8.4406e+00, -1.4239e+00,  7.3861e+00,  5.9170e+00,  2.4842e+01,\n",
       "         -2.9017e+00,  1.4359e+01, -8.5404e+00,  1.7934e+00, -1.8766e+00,\n",
       "         -2.4522e+00, -1.0437e+01,  3.3993e+00, -3.8546e+00, -3.6759e+00,\n",
       "          2.2906e-01, -1.2774e+01,  2.3374e+00,  1.0172e+00,  4.1681e+00,\n",
       "          4.5501e+00,  1.3175e+01,  1.7400e+01,  9.4604e+00,  9.5500e+00,\n",
       "          1.2090e+01,  4.5263e+00,  1.1500e+01,  8.3463e+00,  1.2321e+01,\n",
       "          2.4148e+01,  7.2284e+00,  2.0053e+01,  1.4609e+01,  3.8144e+00]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
