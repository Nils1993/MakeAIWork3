{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.insert(0,\"..\")\n",
    "# from broncode.cnn import CNN\n",
    "# import torchvision.transforms as T\n",
    "# from torchvision.io import read_image, ImageReadMode\n",
    "# import matplotlib as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Subset, Dataset, DataLoader, random_split\n",
    "from torch import nn\n",
    "import torch.nn.functional\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.io import read_image, ImageReadMode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 128, 128])\n",
      "tensor([[[0.9059, 0.9059, 0.9059,  ..., 0.9294, 0.9294, 0.9294],\n",
      "         [0.9059, 0.9059, 0.9059,  ..., 0.9294, 0.9294, 0.9294],\n",
      "         [0.9059, 0.9059, 0.9059,  ..., 0.9294, 0.9294, 0.9294],\n",
      "         ...,\n",
      "         [0.9490, 0.9490, 0.9490,  ..., 0.9725, 0.9725, 0.9725],\n",
      "         [0.9529, 0.9529, 0.9529,  ..., 0.9725, 0.9725, 0.9725],\n",
      "         [0.9529, 0.9529, 0.9529,  ..., 0.9725, 0.9725, 0.9725]],\n",
      "\n",
      "        [[0.9216, 0.9216, 0.9216,  ..., 0.9294, 0.9294, 0.9294],\n",
      "         [0.9216, 0.9216, 0.9216,  ..., 0.9294, 0.9294, 0.9294],\n",
      "         [0.9216, 0.9216, 0.9216,  ..., 0.9294, 0.9294, 0.9294],\n",
      "         ...,\n",
      "         [0.9412, 0.9412, 0.9412,  ..., 0.9529, 0.9529, 0.9529],\n",
      "         [0.9451, 0.9451, 0.9451,  ..., 0.9529, 0.9529, 0.9529],\n",
      "         [0.9451, 0.9451, 0.9451,  ..., 0.9529, 0.9529, 0.9529]],\n",
      "\n",
      "        [[0.9569, 0.9569, 0.9569,  ..., 0.9686, 0.9686, 0.9686],\n",
      "         [0.9569, 0.9569, 0.9569,  ..., 0.9686, 0.9686, 0.9686],\n",
      "         [0.9569, 0.9569, 0.9569,  ..., 0.9686, 0.9686, 0.9686],\n",
      "         ...,\n",
      "         [0.9529, 0.9529, 0.9529,  ..., 0.9765, 0.9765, 0.9765],\n",
      "         [0.9569, 0.9569, 0.9569,  ..., 0.9765, 0.9765, 0.9765],\n",
      "         [0.9569, 0.9569, 0.9569,  ..., 0.9765, 0.9765, 0.9765]]])\n"
     ]
    }
   ],
   "source": [
    "path = \"../informatie/apple_disease_classification/images/Train/Dataset/good_apples/good_apple0.jpg\"\n",
    "img = read_image(path, ImageReadMode.UNCHANGED)/255\n",
    "\n",
    "print(img.shape)\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bad_apples': 0, 'good_apples': 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset_path = \"../informatie/apple_disease_classification/images/Train/Dataset/\"\n",
    "transform = T.ToTensor()\n",
    "dataset = ImageFolder(dataset_path, transform=transform)\n",
    "\n",
    " \n",
    "\n",
    "dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 0 Image shape: torch.Size([3, 128, 128]) Label: 0\n",
      "Sample: 1000 Image shape: torch.Size([3, 128, 128]) Label: 0\n",
      "Sample: 2000 Image shape: torch.Size([3, 128, 128]) Label: 0\n",
      "Sample: 3000 Image shape: torch.Size([3, 128, 128]) Label: 0\n",
      "Sample: 4000 Image shape: torch.Size([3, 128, 128]) Label: 0\n",
      "Sample: 5000 Image shape: torch.Size([3, 128, 128]) Label: 0\n",
      "Sample: 6000 Image shape: torch.Size([3, 128, 128]) Label: 0\n",
      "Sample: 7000 Image shape: torch.Size([3, 128, 128]) Label: 0\n",
      "Sample: 8000 Image shape: torch.Size([3, 128, 128]) Label: 0\n",
      "Sample: 9000 Image shape: torch.Size([3, 128, 128]) Label: 0\n",
      "Sample: 10000 Image shape: torch.Size([3, 128, 128]) Label: 0\n",
      "Sample: 11000 Image shape: torch.Size([3, 128, 128]) Label: 0\n",
      "Sample: 12000 Image shape: torch.Size([3, 128, 128]) Label: 0\n",
      "Sample: 13000 Image shape: torch.Size([3, 128, 128]) Label: 0\n",
      "Sample: 14000 Image shape: torch.Size([3, 128, 128]) Label: 0\n"
     ]
    }
   ],
   "source": [
    "# build subset\n",
    "idx = [i for i in range(len(dataset)) if (dataset.imgs[i][1] == dataset.class_to_idx['bad_apples'] or dataset.imgs[i][1] == dataset.class_to_idx['good_apples']) ]\n",
    "subset = Subset(dataset, idx)\n",
    " \n",
    "\n",
    "\n",
    "for sample_idx in range(len(subset)):\n",
    "    sample = subset[sample_idx]\n",
    "    \n",
    "    # Access the image and label from the sample\n",
    "    image, label = sample\n",
    "    \n",
    "    # Print or examine the sample\n",
    "    if sample_idx % 1000 == 0:\n",
    "        print(\"Sample:\", sample_idx,\"Image shape:\", image.shape,\"Label:\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good apples 208\n",
      "bad apples 14544\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "bad_counter = 0\n",
    "for i in range(len(subset)):\n",
    "    if subset[i][1] == 1:\n",
    "        counter += 1\n",
    "    else:\n",
    "        bad_counter += 1\n",
    "\n",
    "print(\"good apples\", counter)\n",
    "print(\"bad apples\", bad_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8852 2950 2950\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x000001F453A8FAF0>\n"
     ]
    }
   ],
   "source": [
    "generator1 = torch.Generator().manual_seed(13)\n",
    "\n",
    "# create a train test split with 70% train, 30% test\n",
    "train_dataset, test_dataset, val_dataset = random_split(subset, [0.6, 0.2, 0.2], generator=generator1)\n",
    "\n",
    "# check length of train and test dataset\n",
    "print(len(train_dataset), len(test_dataset), len(val_dataset))\n",
    "\n",
    "# create train and test dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, img_size=128, batch_size=64, c_in=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(c_in, 16, 5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn. Conv2d(16, 32, 5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, 5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn. Conv2d(64, 96, 5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Flatten(0),\n",
    "\n",
    "            nn.Linear((img_size*768)*batch_size, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 2),\n",
    "            nn.Softmax(dim=0)\n",
    "            )\n",
    "\n",
    "    def fit(self, train_loader, val_loader, epochs, lr=0.001, opt_function=torch.optim.Adam, loss_func=nn.BCELoss):\n",
    "        optimizer = opt_function(self.model.parameters(),lr )\n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            for batch in train_loader:\n",
    "                image, labels = batch\n",
    "                pred = self(image)\n",
    "                loss = loss_func(pred, labels)\n",
    "                print(loss)\n",
    "\n",
    "\n",
    "               \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "\n",
    "        return self.model(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CNN()\n",
    "net.fit(train_loader, val_loader, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
