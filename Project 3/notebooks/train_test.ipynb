{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"..\")\n",
    "from broncode.cnn import CNN\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Subset, Dataset, DataLoader, random_split\n",
    "from torchvision.io import read_image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bad_apples': 0, 'good_apples': 1}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# The ImageFolder class in torchvision expects the data to be organized in separate folders,\n",
    "# where each folder represents a different class\n",
    " \n",
    "\n",
    "dataset_path = \"../informatie/apple_disease_classification/images/Train/Dataset/\"\n",
    "transform = T.ToTensor()\n",
    "dataset = ImageFolder(dataset_path, transform=transform)\n",
    "\n",
    " \n",
    "\n",
    "dataset.class_to_idx\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 0 Image shape: torch.Size([3, 128, 128]) Label: 0\n",
      "Sample: 1000 Image shape: torch.Size([3, 128, 128]) Label: 0\n",
      "Sample: 2000 Image shape: torch.Size([3, 128, 128]) Label: 0\n",
      "Sample: 3000 Image shape: torch.Size([3, 128, 128]) Label: 0\n",
      "Sample: 4000 Image shape: torch.Size([3, 128, 128]) Label: 0\n",
      "Sample: 5000 Image shape: torch.Size([3, 128, 128]) Label: 0\n",
      "Sample: 6000 Image shape: torch.Size([3, 128, 128]) Label: 0\n",
      "Sample: 7000 Image shape: torch.Size([3, 128, 128]) Label: 0\n",
      "Sample: 8000 Image shape: torch.Size([3, 128, 128]) Label: 0\n",
      "Sample: 9000 Image shape: torch.Size([3, 128, 128]) Label: 0\n",
      "Sample: 10000 Image shape: torch.Size([3, 128, 128]) Label: 0\n",
      "Sample: 11000 Image shape: torch.Size([3, 128, 128]) Label: 0\n",
      "Sample: 12000 Image shape: torch.Size([3, 128, 128]) Label: 0\n",
      "Sample: 13000 Image shape: torch.Size([3, 128, 128]) Label: 0\n",
      "Sample: 14000 Image shape: torch.Size([3, 128, 128]) Label: 0\n"
     ]
    }
   ],
   "source": [
    "# build subset\n",
    "idx = [i for i in range(len(dataset)) if (dataset.imgs[i][1] == dataset.class_to_idx['bad_apples'] or dataset.imgs[i][1] == dataset.class_to_idx['good_apples']) ]\n",
    "subset = Subset(dataset, idx)\n",
    " \n",
    "\n",
    "\n",
    "for sample_idx in range(len(subset)):\n",
    "    sample = subset[sample_idx]\n",
    "    \n",
    "    # Access the image and label from the sample\n",
    "    image, label = sample\n",
    "    \n",
    "    # Print or examine the sample\n",
    "    if sample_idx % 1000 == 0:\n",
    "        print(\"Sample:\", sample_idx,\"Image shape:\", image.shape,\"Label:\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good apples 208\n",
      "bad apples 14544\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "bad_counter = 0\n",
    "for i in range(len(subset)):\n",
    "    if subset[i][1] == 1:\n",
    "        counter += 1\n",
    "    else:\n",
    "        bad_counter += 1\n",
    "\n",
    "print(\"good apples\", counter)\n",
    "print(\"bad apples\", bad_counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10327 4425\n",
      "tensor([[[0.5490, 0.4745, 0.4000,  ..., 0.5373, 0.5843, 0.6275],\n",
      "         [0.6275, 0.5608, 0.4941,  ..., 0.5137, 0.5765, 0.6235],\n",
      "         [0.6078, 0.5569, 0.5098,  ..., 0.4863, 0.5647, 0.6235],\n",
      "         ...,\n",
      "         [0.3569, 0.3882, 0.4235,  ..., 0.3490, 0.3490, 0.3373],\n",
      "         [0.2510, 0.2941, 0.3294,  ..., 0.3373, 0.3333, 0.3176],\n",
      "         [0.1804, 0.2235, 0.2667,  ..., 0.3216, 0.3098, 0.2980]],\n",
      "\n",
      "        [[0.4118, 0.3373, 0.2667,  ..., 0.4706, 0.5098, 0.5490],\n",
      "         [0.4745, 0.4078, 0.3490,  ..., 0.4549, 0.5098, 0.5529],\n",
      "         [0.4275, 0.3843, 0.3412,  ..., 0.4431, 0.5137, 0.5686],\n",
      "         ...,\n",
      "         [0.3765, 0.4157, 0.4588,  ..., 0.3725, 0.3725, 0.3686],\n",
      "         [0.2667, 0.3176, 0.3608,  ..., 0.3529, 0.3490, 0.3412],\n",
      "         [0.1882, 0.2431, 0.2902,  ..., 0.3333, 0.3255, 0.3137]],\n",
      "\n",
      "        [[0.3020, 0.2275, 0.1608,  ..., 0.3608, 0.4510, 0.5059],\n",
      "         [0.3529, 0.2941, 0.2353,  ..., 0.3412, 0.4471, 0.5059],\n",
      "         [0.2941, 0.2471, 0.2157,  ..., 0.3255, 0.4471, 0.5176],\n",
      "         ...,\n",
      "         [0.3922, 0.4392, 0.4941,  ..., 0.0353, 0.0353, 0.0314],\n",
      "         [0.2627, 0.3176, 0.3725,  ..., 0.0118, 0.0078, 0.0000],\n",
      "         [0.1686, 0.2275, 0.2902,  ..., 0.0000, 0.0000, 0.0000]]]) tensor(0)\n"
     ]
    }
   ],
   "source": [
    "# create a random generator\n",
    "generator1 = torch.Generator().manual_seed(13)\n",
    "\n",
    "# create a train test split with 70% train, 30% test\n",
    "train_dataset, test_dataset = random_split(subset, [0.7, 0.3], generator=generator1)\n",
    "\n",
    "# check length of train and test dataset\n",
    "print(len(train_dataset), len(test_dataset))\n",
    "\n",
    "# create train and test dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# train_features, train_labels = next(iter(train_dataloader))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "test_features, test_labels = next(iter(test_dataloader))\n",
    "\n",
    "\n",
    "print(test_features[0], test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 16, 29, 29])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 2704]' is invalid for input of size 861184",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m inputs, labels \u001b[39m=\u001b[39m data\n\u001b[0;32m     20\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 21\u001b[0m outputs \u001b[39m=\u001b[39m net(inputs)  \u001b[39m# forward pass \u001b[39;00m\n\u001b[0;32m     22\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels) \u001b[39m# calculate loss\u001b[39;00m\n\u001b[0;32m     23\u001b[0m loss\u001b[39m.\u001b[39mbackward() \u001b[39m# calculate gradients (training)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\nilsm\\workspace\\MakeAIWork3\\Project 3\\notebooks\\..\\broncode\\cnn.py:49\u001b[0m, in \u001b[0;36mCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39m# To match the output of the conv2 layer onto the first fully connected layer\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[39m# Like reshape() but makes no copy (reuses underlaying data)\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39msize())\n\u001b[1;32m---> 49\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m16\u001b[39;49m \u001b[39m*\u001b[39;49m \u001b[39m13\u001b[39;49m \u001b[39m*\u001b[39;49m \u001b[39m13\u001b[39;49m)\n\u001b[0;32m     51\u001b[0m \u001b[39m# Fully connected layers\u001b[39;00m\n\u001b[0;32m     52\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1(x))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[-1, 2704]' is invalid for input of size 861184"
     ]
    }
   ],
   "source": [
    "def evaluate_accuracy(logits, y_true):\n",
    "    \n",
    "    # get index with the largest logit value PER OBSERVATION\n",
    "    _, y_pred = torch.max(logits, dim=1)\n",
    "    # calculate proportion of correct prediction\n",
    "    correct_pred = (y_pred == y_true).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "\n",
    "    return acc * 100\n",
    "\n",
    "net = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "running_loss = 0 \n",
    "printfreq = 10\n",
    "for epoch in range(2):\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)  # forward pass \n",
    "        loss = criterion(outputs, labels) # calculate loss\n",
    "        loss.backward() # calculate gradients (training)\n",
    "        optimizer.step() # update weights of cnn\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % printfreq == printfreq-1:  \n",
    "            print(epoch, i+1, running_loss / printfreq)\n",
    "            running_loss = 0\n",
    "    \n",
    "    \n",
    "    # disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "        # initialize tracker for validation performance\n",
    "        val_acc = 0\n",
    "        val_loss = 0\n",
    "\n",
    "        # prepare model for evaluation\n",
    "        net.eval()\n",
    "\n",
    "        # loop for each batch\n",
    "        for data, target in test_dataloader:\n",
    "            # STEP 1: forward pass\n",
    "            output = net(data)\n",
    "            # STEP 2: calculate the loss\n",
    "            loss = criterion(output, target)\n",
    "            # STEP 3: accumulate validation loss and accuracy\n",
    "            acc = evaluate_accuracy(output, target)\n",
    "        \n",
    "        print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
