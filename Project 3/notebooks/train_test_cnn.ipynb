{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Train and test the CNN</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from broncode.apple_classifyer import AppleClassifyer\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Subset, Dataset, DataLoader, random_split\n",
    "from torch import nn\n",
    "import torch.nn.functional\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "import torch\n",
    "import pickle as pkl\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../informatie/apple_disease_classification/images/Train/Dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to create a dataset.\n",
    "class DatasetAppels(Dataset):\n",
    "    def __init__(self, img_folder_path, transform):\n",
    "        # I use the function ImageFolder from pytorch to do most of the heavy lifting for me.\n",
    "        image_folder = ImageFolder(img_folder_path, transform=transform)\n",
    "        print(image_folder.classes)\n",
    "        # I create images and labels variables for later use.\n",
    "        self.images = [image[0] for image in image_folder]\n",
    "        self.labels = image_folder.targets\n",
    "        self.class_dict = image_folder.class_to_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    # Function to retrieve an image and/or label at specified index.\n",
    "    def __getitem__(self, idx):\n",
    "    \n",
    "        return [self.images[idx], self.labels[idx]]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the class and create a dataset.\n",
    "dataset = DatasetAppels(dataset_path, T.ToTensor())\n",
    "\n",
    "next(iter(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I decided to resize my images to 64 by 64 for faster training and less memory usage.\n",
    "resize_data = T.Resize((64,64))\n",
    "print(dataset.images[0].shape)\n",
    "\n",
    "for i in range(len(dataset.images)):\n",
    "    dataset.images[i] = resize_data(dataset.images[i])\n",
    "\n",
    "print(dataset.images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator1 = torch.Generator().manual_seed(13)\n",
    "\n",
    "# create a train test split with 60% train, 20% test, 20% val. For later use\n",
    "train_dataset, test_dataset, val_dataset = random_split(dataset, [0.6, 0.2, 0.2], generator=generator1)\n",
    "print(len(train_dataset), len(test_dataset), len(val_dataset))\n",
    "\n",
    "# Create train, test and val dataloaders for later use.\n",
    "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=50, shuffle=False)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=50, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to train!\n",
    "net = AppleClassifyer()\n",
    "# After fiddeling a lot, this is the learningrate/epochs I had the best result with\n",
    "history, acc = net.fit(train_loader, val_loader, test_loader, lr = 0.0015, epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I created a function in my AppleClassifyer() to predict a single image so I can test with different images and use this function for the aql function later on.\n",
    "\n",
    "# Lets try with normal images\n",
    "normal = [32, 33, 34]\n",
    "\n",
    "for i in normal:\n",
    "    test_path = f\"../informatie/apple_disease_classification/images/Test/Normal_Apple/{i}.jpg\"\n",
    "    test_img = read_image(test_path, ImageReadMode.RGB)/255\n",
    "    test_img = resize_data(test_img)\n",
    "\n",
    "    # Since the model expects a batch I have to use the unsqueeze() function\n",
    "    test_img = test_img.unsqueeze(0)\n",
    "    result = net.predict_image(test_img)\n",
    "    print(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I then use pickle as pkl to save the model using the acc (accuracy percentage) in the filename. I don't mind if it overwrites an older one with the same percentage.\n",
    "model_path = f\"..//models/AppleClassifyer_{acc}\"\n",
    "\n",
    "with open(model_path, 'wb') as f:\n",
    "        pkl.dump(net, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
